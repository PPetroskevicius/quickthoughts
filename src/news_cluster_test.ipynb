{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "start = time.time()\n",
    "\n",
    "checkpoint_dir = '/home/jcaip/workspace/quickthoughts/checkpoints/fluid_embeddings'\n",
    "with open(\"{}/config.json\".format(checkpoint_dir)) as fp:\n",
    "    CONFIG = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 08:22:43 INFO     loading projection weights from /home/jcaip/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2019-07-12 08:22:43 WARNING  this function is deprecated, use smart_open.open instead\n",
      "2019-07-12 08:24:50 INFO     loaded (400000, 300) matrix from /home/jcaip/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "/home/jcaip/.conda/envs/ml/lib/python3.7/site-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored successfully from /home/jcaip/workspace/quickthoughts/checkpoints/fluid_embeddings\n"
     ]
    }
   ],
   "source": [
    "WV_MODEL = api.load(CONFIG['embedding'])\n",
    "qt = QuickThoughts(WV_MODEL, hidden_size=CONFIG['hidden_size'])\n",
    "trained_params = torch.load(\"{}/checkpoint_latest.pth\".format(checkpoint_dir))\n",
    "qt.load_state_dict(trained_params['state_dict'])\n",
    "qt = qt.cuda()\n",
    "qt.eval()\n",
    "print(\"Restored successfully from {}\".format(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset 20 NEWS with total lines: 18846\n",
      "Processing    19 batches of size  1000\n",
      "Test feature matrix of shape: (18846, 2000)\n"
     ]
    }
   ],
   "source": [
    "text, labels = newsgroups.data, newsgroups.target\n",
    "test_batch_size=1000\n",
    "size = len(labels)\n",
    "print(\"Loaded dataset {} with total lines: {}\".format(\"20 NEWS\", size))\n",
    "\n",
    "def make_batch(j):\n",
    "    \"\"\"Processes one test batch of the test datset\"\"\"\n",
    "    stop_idx = min(size, j+test_batch_size)\n",
    "    batch_text, batch_labels  = text[j:stop_idx], labels[j:stop_idx]\n",
    "    data = list(map(lambda x: torch.LongTensor(prepare_sequence(x, WV_MODEL.vocab, no_zeros=True)), batch_text))\n",
    "    for i in data:\n",
    "        if len(i) == 0:\n",
    "            print(i)\n",
    "            input()\n",
    "    packed = safe_pack_sequence(data).cuda()\n",
    "    return qt(packed).cpu().detach().numpy()\n",
    "\n",
    "feature_list = [make_batch(i) for i in range(0, size, test_batch_size)]\n",
    "print(\"Processing {:5d} batches of size {:5d}\".format(len(feature_list), test_batch_size))\n",
    "features = np.concatenate(feature_list)\n",
    "print(\"Test feature matrix of shape: {}\".format(features.shape))\n",
    "\n",
    "#shuffle\n",
    "features, labels = shuffle(features, labels)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, labels)\n",
    "#acc_t = fit_clf(X_train, y_train, X_test, y_test, 1)\n",
    "#print(\"Trained on {:4d} examples - Test Accuracy: {:.2%}\".format(len(X_train), acc_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "\n",
    "predicted_kmeans = KMeans(n_clusters=20, verbose=0).fit_predict(features[:5000])\n",
    "predicted_spectral = SpectralClustering(n_clusters=20).fit_predict(features[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_embedded = TSNE(n_components=2, verbose=1).fit_transform(features[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 5, figsize=(20, 15))\n",
    "\n",
    "fixed_xlim, fixed_ylim = (-85.6129455010451, 110.84618372125996), (-90.00594782812799, 80.691349744632)\n",
    "\n",
    "for i in range(20):\n",
    "    selected = feature_embedded[labels[:5000] == i]\n",
    "    ax = axs[i//5, i%5]\n",
    "    ax.scatter(selected[:, 0], selected[:, 1])\n",
    "    ax.set_ylim(fixed_ylim)\n",
    "    ax.set_xlim(fixed_xlim)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 5, figsize=(20, 15))\n",
    "\n",
    "fixed_xlim, fixed_ylim = (-85.6129455010451, 110.84618372125996), (-90.00594782812799, 80.691349744632)\n",
    "\n",
    "for i in range(20):\n",
    "    selected = feature_embedded[predicted_spectral[:5000] == i]\n",
    "    ax = axs[i//5, i%5]\n",
    "    ax.scatter(selected[:, 0], selected[:, 1])\n",
    "    ax.set_ylim(fixed_ylim)\n",
    "    ax.set_xlim(fixed_xlim)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 5, figsize=(20, 15))\n",
    "\n",
    "fixed_xlim, fixed_ylim = (-85.6129455010451, 110.84618372125996), (-90.00594782812799, 80.691349744632)\n",
    "\n",
    "for i in range(20):\n",
    "    selected = feature_embedded[predicted_kmeans[:5000] == i]\n",
    "    ax = axs[i//5, i%5]\n",
    "    ax.scatter(selected[:, 0], selected[:, 1])\n",
    "    ax.set_ylim(fixed_ylim)\n",
    "    ax.set_xlim(fixed_xlim)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(\"\\nCategoty: {}\\n\".format(i))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    for j in np.argsort(predicted_cluster[:, i])[:1]:\n",
    "        print(\"Example :{}\".format(j))\n",
    "        print(text[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
